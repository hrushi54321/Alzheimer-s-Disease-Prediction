{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_Concatenated.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qmDKDYRpizsk",
        "iFf5zITzH9I1",
        "DMRU-tfxH0N-",
        "D4lelhTRJQRE",
        "u4GiuOjJk_ff",
        "RXsfdGHQvIq-",
        "5pSP2XsdzIlE",
        "sZcNRG1W20W1",
        "CSBfzgcjpEhJ",
        "4Uiam_nY3QBd",
        "HybwdjXMqL3n",
        "Tjm4SJuh34qV",
        "n7-pfucFW6oU",
        "Rn_9QPUEq0YJ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRR0gIpiVdF"
      },
      "source": [
        "#Imports and Uploads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7E7XNG0iJnA"
      },
      "source": [
        "'''\n",
        "The four files need to be uploaded onto the colab environment:\n",
        "COG.csv, PHENO.csv, MRI.csv, DEMO.csv\n",
        "It can be uploaded by running this cell\n",
        "'''\n",
        "from google.colab import files\n",
        "m,p,d,i = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3oCzTfXiZIN"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import GRU\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.impute import KNNImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCjVCTHvia8P"
      },
      "source": [
        "#Once the files are uploaded onto the environment\n",
        "pheno = pd.read_csv('PHENO.csv')\n",
        "mri = pd.read_csv('MRI.csv')\n",
        "demo = pd.read_csv('DEMO.csv')\n",
        "cog = pd.read_csv('COG.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwf7EooPic2F"
      },
      "source": [
        "pheno = pheno.sort_values(by = ['RID'])\n",
        "print(\"Pheno: \\n\")\n",
        "print(pheno.head())\n",
        "mri = mri.sort_values(by = ['RID'])\n",
        "print(\"\\n MRI: \\n\")\n",
        "print(mri.head())\n",
        "demo = demo.sort_values(by = ['RID'])\n",
        "print(\"\\n Demo: \\n\")\n",
        "print(demo.head())\n",
        "cog = cog.sort_values(by = ['RID'])\n",
        "print(\"\\n Cog: \\n\")\n",
        "print(cog.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmDKDYRpizsk"
      },
      "source": [
        "##Demo Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJCrI1qDi1sq"
      },
      "source": [
        "'''\n",
        "Formatting the data as well as removing the data which contain too many missing \n",
        "values.\n",
        "'''\n",
        "Age = []\n",
        "Apoe4 = []\n",
        "labels_demo = []\n",
        "start = 2\n",
        "rids_demo = []\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 Age\n",
        "l2 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 Apoe4\n",
        "cnt = 0\n",
        "for index,row in demo.iterrows():\n",
        "  if start != row['RID']:    \n",
        "    if sum(l1) != 0 and sum(l2) != 0 and cnt>1:\n",
        "      rids_demo.append(row['RID'])\n",
        "      Age.append(l1)\n",
        "      Apoe4.append(l2)\n",
        "      if dec == 'AD':\n",
        "        labels_demo.append(1)\n",
        "      else:\n",
        "        labels_demo.append(0)\n",
        "    l1 = [0,0,0,0,0,0]\n",
        "    l2 = [0,0,0,0,0,0]\n",
        "    start = row['RID']\n",
        "    cnt=0\n",
        "  dec = row['DX_bl']\n",
        "  m = row['VISCODE']\n",
        "  ptm = row['AGE']\n",
        "  ptt = row['APOE4']\n",
        "  if m == 'bl':\n",
        "    cnt+=1\n",
        "    l1[0] = ptm\n",
        "    l2[0] = ptt\n",
        "  elif m == 'm06':\n",
        "    cnt+=1\n",
        "    l1[1] = ptm\n",
        "    l2[1] = ptt\n",
        "  elif m == 'm12':\n",
        "    cnt+=1\n",
        "    l1[2] = ptm\n",
        "    l2[2] = ptt\n",
        "  elif m == 'm24':\n",
        "    cnt+=1\n",
        "    l1[3] = ptm\n",
        "    l2[3] = ptt\n",
        "  elif m == 'm36':\n",
        "    cnt+=1\n",
        "    l1[4] = ptm\n",
        "    l2[4] = ptt\n",
        "  elif m == 'm48':\n",
        "    cnt+=1\n",
        "    l1[5] = ptm\n",
        "    l2[5] = ptt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra9tc1lCmms4"
      },
      "source": [
        "x1 = np.array(Age)\n",
        "x2 = np.array(Apoe4)\n",
        "#Length of data in Cog\n",
        "print(len(x1),len(x2))\n",
        "y_demo = np.array(labels_demo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXkeoAMXmpeU"
      },
      "source": [
        "#KNN Imputation is done to fill in the few missing values which are left\n",
        "imputer = KNNImputer(n_neighbors=28, missing_values=0, weights = 'distance')\n",
        "x1_demo = imputer.fit_transform(x1)  #Age\n",
        "x2_demo = imputer.fit_transform(x2)  #APOE4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrhSAxz9mr9r"
      },
      "source": [
        "lAge = x1_demo.tolist()\n",
        "lApoe4 = x2_demo.tolist()\n",
        "print(lAge)\n",
        "print(lApoe4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFf5zITzH9I1"
      },
      "source": [
        "##Cog Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YmfsotmpSiL"
      },
      "source": [
        "'''\n",
        "Formatting the data as well as removing the data which contain too many missing \n",
        "values.\n",
        "'''\n",
        "CogPtMem = []\n",
        "CogPtTotal = []\n",
        "labels_cog = []\n",
        "start = 2\n",
        "rids_cog = []\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTMEM\n",
        "l2 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTTOT\n",
        "cnt = 0\n",
        "for index,row in cog.iterrows():\n",
        "  if start != row['RID']:    \n",
        "    if sum(l1) != 0 and sum(l2) != 0 and cnt>1:\n",
        "      rids_cog.append(row['RID'])\n",
        "      CogPtMem.append(l1)\n",
        "      CogPtTotal.append(l2)\n",
        "      if dec == 'AD':\n",
        "        labels_cog.append(1)\n",
        "      else:\n",
        "        labels_cog.append(0)\n",
        "    l1 = [0,0,0,0,0,0]\n",
        "    l2 = [0,0,0,0,0,0]\n",
        "    start = row['RID']\n",
        "    cnt=0\n",
        "  dec = row['DX_bl']\n",
        "  m = row['VISCODE']\n",
        "  ptm = row['EcogPtMem']\n",
        "  ptt = row['EcogPtTotal']\n",
        "  if m == 'bl':\n",
        "    cnt+=1\n",
        "    l1[0] = ptm\n",
        "    l2[0] = ptt\n",
        "  elif m == 'm06':\n",
        "    cnt+=1\n",
        "    l1[1] = ptm\n",
        "    l2[1] = ptt\n",
        "  elif m == 'm12':\n",
        "    cnt+=1\n",
        "    l1[2] = ptm\n",
        "    l2[2] = ptt\n",
        "  elif m == 'm24':\n",
        "    cnt+=1\n",
        "    l1[3] = ptm\n",
        "    l2[3] = ptt\n",
        "  elif m == 'm36':\n",
        "    cnt+=1\n",
        "    l1[4] = ptm\n",
        "    l2[4] = ptt\n",
        "  elif m == 'm48':\n",
        "    cnt+=1\n",
        "    l1[5] = ptm\n",
        "    l2[5] = ptt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ePPJtnU4qjQ"
      },
      "source": [
        "x1 = np.array(CogPtMem)\n",
        "x2 = np.array(CogPtTotal)\n",
        "#Length of data in Cog\n",
        "print(len(x1),len(x2))\n",
        "y_cog = np.array(labels_cog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ1YIi364waM"
      },
      "source": [
        "#KNN Imputation is done to fill in the few missing values which are left\n",
        "imputer = KNNImputer(n_neighbors=28, missing_values=0, weights = 'distance')\n",
        "x1_cog = imputer.fit_transform(x1)  #CogPtMem\n",
        "x2_cog = imputer.fit_transform(x2)  #CogPtTotal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eINk1o2K6Sqr"
      },
      "source": [
        "lCogPtMem = x1_cog.tolist()\n",
        "lCogPtTotal = x2_cog.tolist()\n",
        "print(lCogPtMem)\n",
        "print(lCogPtTotal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMRU-tfxH0N-"
      },
      "source": [
        "##Pheno Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqmW31bJqA1Y"
      },
      "source": [
        "'''\n",
        "Formatting the data as well as removing the data which contain too many missing \n",
        "values.\n",
        "'''\n",
        "abeta = []\n",
        "tau = []\n",
        "ptau = []\n",
        "labels_pheno = []\n",
        "start = 3\n",
        "rids_pheno = []\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 abeta\n",
        "l2 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 tau\n",
        "l3 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 ptau\n",
        "cnt = 0\n",
        "for index,row in pheno.iterrows():\n",
        "  if start != row['RID']:    \n",
        "    if sum(l1) != 0 and sum(l2) != 0 and sum(l3) != 0 and cnt>1:\n",
        "      rids_pheno.append(row['RID'])\n",
        "      abeta.append(l1)\n",
        "      tau.append(l2)\n",
        "      ptau.append(l3)\n",
        "      if dec == 'AD':\n",
        "        labels_pheno.append(1)\n",
        "      else:\n",
        "        labels_pheno.append(0)\n",
        "    l1 = [0,0,0,0,0,0]\n",
        "    l2 = [0,0,0,0,0,0]\n",
        "    l3 = [0,0,0,0,0,0]\n",
        "    start = row['RID']\n",
        "    cnt=0\n",
        "  dec = row['DX_bl']\n",
        "  m = row['VISCODE']\n",
        "  abt = row['ABETA']\n",
        "  ta = row['TAU']\n",
        "  pta = row['PTAU']\n",
        "  if m == 'bl':\n",
        "    cnt+=1\n",
        "    l1[0] = abt\n",
        "    l2[0] = ta\n",
        "    l3[0] = pta\n",
        "  elif m == 'm06':\n",
        "    cnt+=1\n",
        "    l1[1] = abt\n",
        "    l2[1] = ta\n",
        "    l3[1] = pta\n",
        "  elif m == 'm12':\n",
        "    cnt+=1\n",
        "    l1[2] = abt\n",
        "    l2[2] = ta\n",
        "    l3[2] = pta\n",
        "  elif m == 'm24':\n",
        "    cnt+=1\n",
        "    l1[3] = abt\n",
        "    l2[3] = ta\n",
        "    l3[3] = pta\n",
        "  elif m == 'm36':\n",
        "    cnt+=1\n",
        "    l1[4] = abt\n",
        "    l2[4] = ta\n",
        "    l3[4] = pta\n",
        "  elif m == 'm48':\n",
        "    cnt+=1\n",
        "    l1[5] = abt\n",
        "    l2[5] = ta\n",
        "    l3[5] = pta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpl4MJob6xWk"
      },
      "source": [
        "x1_pheno = np.array(abeta)\n",
        "x2_pheno = np.array(tau)\n",
        "x3_pheno = np.array(ptau)\n",
        "y_pheno = np.array(labels_pheno)\n",
        "print(len(x1_pheno))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6VqFOpx6zho"
      },
      "source": [
        "#Imputation\n",
        "imputer = KNNImputer(n_neighbors=16, missing_values=0, weights = 'distance')\n",
        "x1_pheno = imputer.fit_transform(x1_pheno) #ABETA\n",
        "x2_pheno = imputer.fit_transform(x2_pheno) #TAU\n",
        "x3_pheno = imputer.fit_transform(x3_pheno) #PTAU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aGcrrzK62VB"
      },
      "source": [
        "labeta = x1_pheno.tolist()\n",
        "ltau = x2_pheno.tolist()\n",
        "lptau = x3_pheno.tolist()\n",
        "print(labeta)\n",
        "print(ltau)\n",
        "print(lptau)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4lelhTRJQRE"
      },
      "source": [
        "##MRI Formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-tcmQALJS3z"
      },
      "source": [
        "hippo = []\n",
        "entor = []\n",
        "labels_mri = []\n",
        "start = 2\n",
        "rids_mri = []\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTMEM\n",
        "l2 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTTOT\n",
        "cnt = 0\n",
        "for index,row in mri.iterrows():\n",
        "  if start != row['RID']:   \n",
        "    if sum(l1) != 0 and sum(l2) != 0 and cnt>1:\n",
        "      rids_mri.append(row['RID'])\n",
        "      hippo.append(l1)\n",
        "      entor.append(l2)\n",
        "      if dec == 'AD':\n",
        "        labels_mri.append(1)\n",
        "      else:\n",
        "        labels_mri.append(0)\n",
        "    l1 = [0,0,0,0,0,0]\n",
        "    l2 = [0,0,0,0,0,0]\n",
        "    start = row['RID']\n",
        "    cnt=0\n",
        "  dec = row['DX_bl']\n",
        "  m = row['VISCODE']\n",
        "  hi = row['Hippocampus']\n",
        "  en = row['Entorhinal']\n",
        "  if m == 'bl':\n",
        "    cnt+=1\n",
        "    l1[0] = hi\n",
        "    l2[0] = en\n",
        "  elif m == 'm06':\n",
        "    cnt+=1\n",
        "    l1[1] = hi\n",
        "    l2[1] = en\n",
        "  elif m == 'm12':\n",
        "    cnt+=1\n",
        "    l1[2] = hi\n",
        "    l2[2] = en\n",
        "  elif m == 'm24':\n",
        "    cnt+=1\n",
        "    l1[3] = hi\n",
        "    l2[3] = en\n",
        "  elif m == 'm36':\n",
        "    cnt+=1\n",
        "    l1[4] = hi\n",
        "    l2[4] = en\n",
        "  elif m == 'm48':\n",
        "    cnt+=1\n",
        "    l1[5] = hi\n",
        "    l2[5] = en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5JeFbrf7J0T"
      },
      "source": [
        "x1_mri = np.array(hippo)\n",
        "x2_mri = np.array(entor)\n",
        "y_mri = np.array(labels_mri)\n",
        "print(len(x1_mri),len(x2_mri))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M35faw_07NEs"
      },
      "source": [
        "imputer = KNNImputer(n_neighbors=32, missing_values=0, weights = 'distance')\n",
        "x1_mri = imputer.fit_transform(x1_mri) #Hippocampus\n",
        "x2_mri = imputer.fit_transform(x2_mri) #Entorhinal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzBzPhwU7NtY"
      },
      "source": [
        "lhippo = x1_mri.tolist()\n",
        "lentor = x2_mri.tolist()\n",
        "print(lhippo)\n",
        "print(lentor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4GiuOjJk_ff"
      },
      "source": [
        "##Adding Patients of different modalities to each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udIHdrNSJE_c"
      },
      "source": [
        "#Adding patients from Pheno rids to Cog rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTMEM and PTTOT\n",
        "cnt = -1\n",
        "for i in rids_pheno:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_cog:\n",
        "    rids_cog.append(i)\n",
        "    lCogPtMem.append(l1)\n",
        "    lCogPtTotal.append(l1)\n",
        "    labels_cog.append(labels_pheno[cnt])\n",
        "\n",
        "#Adding patients from MRI rids to Cog rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 PTMEM and PTTOT\n",
        "cnt = -1\n",
        "for i in rids_mri:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_cog:\n",
        "    rids_cog.append(i)\n",
        "    lCogPtMem.append(l1)\n",
        "    lCogPtTotal.append(l1)\n",
        "    labels_cog.append(labels_mri[cnt])\n",
        "\n",
        "#Adding Patients from Cog rids to Pheno rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 abeta, tau, ptau\n",
        "cnt = -1\n",
        "for i in rids_cog:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_pheno:\n",
        "    rids_pheno.append(i)\n",
        "    labeta.append(l1)\n",
        "    ltau.append(l1)\n",
        "    lptau.append(l1)\n",
        "    labels_pheno.append(labels_cog[cnt])\n",
        "\n",
        "#Adding Patients from MRI rids to Pheno rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 abeta, tau, ptau\n",
        "cnt = -1\n",
        "for i in rids_mri:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_pheno:\n",
        "    rids_pheno.append(i)\n",
        "    labeta.append(l1)\n",
        "    ltau.append(l1)\n",
        "    lptau.append(l1)\n",
        "    labels_pheno.append(labels_mri[cnt])\n",
        "\n",
        "#Adding patients from Cog rids to MRI rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 hippo, entor\n",
        "cnt = -1\n",
        "for i in rids_cog:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_mri:\n",
        "    rids_mri.append(i)\n",
        "    lhippo.append(l1)\n",
        "    lentor.append(l1)\n",
        "    labels_mri.append(labels_cog[cnt])\n",
        "\n",
        "#Adding patients from Pheno rids to MRI rids\n",
        "l1 = [0,0,0,0,0,0] #bl, m06, m12, m24, m36, m48 hippo, entor\n",
        "cnt = -1\n",
        "for i in rids_pheno:\n",
        "  cnt = cnt + 1\n",
        "  if i not in rids_mri:\n",
        "    rids_mri.append(i)\n",
        "    lhippo.append(l1)\n",
        "    lentor.append(l1)\n",
        "    labels_mri.append(labels_pheno[cnt])\n",
        "\n",
        "print(len(rids_cog))\n",
        "print(len(rids_pheno))\n",
        "print(len(rids_mri))\n",
        "print(len(labels_cog))\n",
        "print(len(labels_pheno))\n",
        "print(len(labels_mri))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXsfdGHQvIq-"
      },
      "source": [
        "##Handle Demo Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTOvv8eOuynG"
      },
      "source": [
        "# using dictionary comprehension \n",
        "# to convert lists to dictionary \n",
        "d_Age = {rids_demo[i]: lAge[i] for i in range(len(rids_demo))} \n",
        "d_Apoe4 = {rids_demo[i]: lApoe4[i] for i in range(len(rids_demo))} \n",
        "d_Labels = {rids_demo[i]: labels_demo[i] for i in range(len(rids_demo))} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVLdPancwXyb"
      },
      "source": [
        "print(len(d_Age))\n",
        "print(len(d_Apoe4))\n",
        "print(len(d_Labels))\n",
        "print(d_Age)\n",
        "print(d_Apoe4)\n",
        "print(d_Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpdSfy4Awnpo"
      },
      "source": [
        "rids_demos = []\n",
        "lAges = []\n",
        "lApoes4 = []\n",
        "l1 = [0,0,0,0,0,0]\n",
        "\n",
        "print(len(rids_demo))\n",
        "print(len(lAge))\n",
        "print(len(lApoe4))\n",
        "for i in rids_cog:\n",
        "  if i in d_Age.keys():\n",
        "    rids_demos.append(i)\n",
        "    lAges.append(d_Age[i])\n",
        "    lApoes4.append(d_Apoe4[i])\n",
        "  elif i not in d_Age.keys():\n",
        "    rids_demos.append(i)\n",
        "    lAges.append(l1)\n",
        "    lApoes4.append(l1)\n",
        "\n",
        "print(len(rids_demos))\n",
        "print(len(lAges))\n",
        "print(len(lApoes4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHtLdNd7yM_H"
      },
      "source": [
        "x1 = np.array(lAges)\n",
        "x2 = np.array(lApoes4)\n",
        "#Length of data in Demo\n",
        "print(len(x1),len(x2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE0G06LXyWhO"
      },
      "source": [
        "#KNN Imputation is done to fill in the few missing values which are left\n",
        "imputer = KNNImputer(n_neighbors=28, missing_values=0, weights = 'distance')\n",
        "x1_demo = imputer.fit_transform(x1)  #Age\n",
        "x2_demo = imputer.fit_transform(x2)  #Apoe4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-JQ52ACydqT"
      },
      "source": [
        "##GRU for Demo Final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKtCNkgcyf1o"
      },
      "source": [
        "#GRUs require 3 dimensional input\n",
        "x1_demo = x1_demo.reshape((1,1776,6))\n",
        "x2_demo = x2_demo.reshape((1,1776,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMg0I_uWykRx"
      },
      "source": [
        "#Generating feature vectors\n",
        "inputs0 = Input(shape=(1776, 6))\n",
        "gru0 = GRU(6, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state = gru0(inputs0)\n",
        "model0 = Model(inputs=inputs0, outputs=whole_sequence_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCz673q9ymVt"
      },
      "source": [
        "lage_fv = model0.predict(x1_demo) #Age: fv = feature vector\n",
        "lapoe4_fv = model0.predict(x2_demo) #APOE4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pSP2XsdzIlE"
      },
      "source": [
        "##Converting Demo Feature Vectors and Labels to Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY0HbjnnzH8X"
      },
      "source": [
        "lage_fv_list = lage_fv[0].tolist()\n",
        "print(lage_fv_list)\n",
        "lapoe4_fv_list = lapoe4_fv[0].tolist()\n",
        "print(lapoe4_fv_list)\n",
        "\n",
        "dic_lage = {rids_demos[i]: lage_fv_list[i] for i in range(len(rids_demos))}\n",
        "dic_lapoe4 = {rids_demos[i]: lapoe4_fv_list[i] for i in range(len(rids_demos))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZcNRG1W20W1"
      },
      "source": [
        "##Imputing COG values for additional patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wx5Z4CM1qBE"
      },
      "source": [
        "x1 = np.array(lCogPtMem)\n",
        "x2 = np.array(lCogPtTotal)\n",
        "#Length of data in Cog\n",
        "print(len(x1),len(x2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36zS9zau18--"
      },
      "source": [
        "#KNN Imputation is done to fill in the few missing values which are left\n",
        "imputer = KNNImputer(n_neighbors=28, missing_values=0, weights = 'distance')\n",
        "x1_cog = imputer.fit_transform(x1)  #CogPtMem\n",
        "x2_cog = imputer.fit_transform(x2)  #CogPtTotal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BO1QH_sSpjK"
      },
      "source": [
        "###GRU for COG final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PCW4PKDSirh"
      },
      "source": [
        "#GRUs require 3 dimensional input\n",
        "x1_cog = x1_cog.reshape((1,1776,6))\n",
        "x2_cog = x2_cog.reshape((1,1776,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCgHM673SnHI"
      },
      "source": [
        "#Generating feature vectors\n",
        "inputs1 = Input(shape=(1776, 6))\n",
        "gru1 = GRU(6, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state = gru1(inputs1)\n",
        "model1 = Model(inputs=inputs1, outputs=whole_sequence_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtaBm0YrSo7Q"
      },
      "source": [
        "cogptmem_fv = model1.predict(x1_cog) #CogPtMem: fv = feature vector\n",
        "cogpttotal_fv = model1.predict(x2_cog) #CogPtTotal\n",
        "print(cogptmem_fv)\n",
        "print(cogpttotal_fv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSBfzgcjpEhJ"
      },
      "source": [
        "##Converting Cog Feature Vectors and Labels to Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjgmxKWMmlx-"
      },
      "source": [
        "cogptmem_fv_list = cogptmem_fv[0].tolist()\n",
        "print(cogptmem_fv_list)\n",
        "cogpttotal_fv_list = cogpttotal_fv[0].tolist()\n",
        "print(cogpttotal_fv_list)\n",
        "\n",
        "dic_cogptmem = {rids_cog[i]: cogptmem_fv_list[i] for i in range(len(rids_cog))}\n",
        "dic_cogpttotal = {rids_cog[i]: cogpttotal_fv_list[i] for i in range(len(rids_cog))}\n",
        "dic_cog_labels = {rids_cog[i]: labels_cog[i] for i in range(len(rids_cog))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-IVR5Wfnjdh"
      },
      "source": [
        "print(dic_cogptmem)\n",
        "print(dic_cogpttotal)\n",
        "print(dic_cog_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uiam_nY3QBd"
      },
      "source": [
        "##Imputing Pheno values for additional patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dg-u9Gw3Pm8"
      },
      "source": [
        "x1_pheno1 = np.array(labeta)\n",
        "x2_pheno1 = np.array(ltau)\n",
        "x3_pheno1 = np.array(lptau)\n",
        "print(len(x1_pheno1),len(x2_pheno1),len(x3_pheno1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7LwqLxx3j5F"
      },
      "source": [
        "#Imputation\n",
        "imputer = KNNImputer(n_neighbors=16, missing_values=0, weights = 'distance')\n",
        "x1_pheno = imputer.fit_transform(x1_pheno1) #ABETA\n",
        "x2_pheno = imputer.fit_transform(x2_pheno1) #TAU\n",
        "x3_pheno = imputer.fit_transform(x3_pheno1) #PTAU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9uiptb1VrsK"
      },
      "source": [
        "print(x1_pheno)\n",
        "print(x2_pheno)\n",
        "print(x3_pheno)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvlLDeHZT5pW"
      },
      "source": [
        "###GRU for Pheno final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D5VR1kTT8Zn"
      },
      "source": [
        "#GRUs require 3 dimensional input\n",
        "x1_pheno = x1_pheno.reshape((1,1776,6))\n",
        "x2_pheno = x2_pheno.reshape((1,1776,6))\n",
        "x3_pheno = x3_pheno.reshape((1,1776,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lv0YD8yUdDo"
      },
      "source": [
        "#Normalizing all data\n",
        "x1_pheno = x1_pheno/400.0\n",
        "x2_pheno = x2_pheno/200.0\n",
        "x3_pheno = x3_pheno/50.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJAtZv2hUOyL"
      },
      "source": [
        "#Generating feature vectors\n",
        "inputs2 = Input(shape=(1776, 6))\n",
        "gru2 = GRU(6, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state = gru2(inputs2)\n",
        "model2 = Model(inputs=inputs2, outputs=whole_sequence_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQknOLKIUob5"
      },
      "source": [
        "abeta_fv = model2.predict(x1_pheno)\n",
        "tau_fv = model2.predict(x2_pheno)\n",
        "ptau_fv = model2.predict(x3_pheno)\n",
        "print(abeta_fv)\n",
        "print(tau_fv)\n",
        "print(ptau_fv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HybwdjXMqL3n"
      },
      "source": [
        "##Converting Pheno Feature Vectors and Labels to Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaULvwYTpOQ_"
      },
      "source": [
        "abeta_fv_list = abeta_fv[0].tolist()\n",
        "print(abeta_fv_list)\n",
        "tau_fv_list = tau_fv[0].tolist()\n",
        "print(tau_fv_list)\n",
        "ptau_fv_list = ptau_fv[0].tolist()\n",
        "print(ptau_fv_list)\n",
        "\n",
        "dic_abeta = {rids_pheno[i]: abeta_fv_list[i] for i in range(len(rids_pheno))}\n",
        "dic_tau = {rids_pheno[i]: tau_fv_list[i] for i in range(len(rids_pheno))}\n",
        "dic_ptau = {rids_pheno[i]: ptau_fv_list[i] for i in range(len(rids_pheno))}\n",
        "dic_pheno_labels = {rids_pheno[i]: labels_pheno[i] for i in range(len(rids_pheno))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h05YZITRpyep"
      },
      "source": [
        "print(dic_abeta)\n",
        "print(dic_tau)\n",
        "print(dic_ptau)\n",
        "print(dic_pheno_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjm4SJuh34qV"
      },
      "source": [
        "##Imputing MRI values for additional patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MXzeOjq3790"
      },
      "source": [
        "x1_mri1 = np.array(lhippo)\n",
        "x2_mri1 = np.array(lentor)\n",
        "print(len(x1_mri1),len(x2_mri1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUC4YG9b4FSf"
      },
      "source": [
        "imputer = KNNImputer(n_neighbors=32, missing_values=0, weights = 'distance')\n",
        "x1_mri = imputer.fit_transform(x1_mri1) #Hippocampus\n",
        "x2_mri = imputer.fit_transform(x2_mri1) #Entorhinal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lfil5o64MP0"
      },
      "source": [
        "print(x1_mri)\n",
        "print(len(x1_mri))\n",
        "print(x2_mri)\n",
        "print(len(x2_mri))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-pfucFW6oU"
      },
      "source": [
        "###GRU for MRI final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnier4ubXQre"
      },
      "source": [
        "#Reshaping for GRU\n",
        "x1_mri = x1_mri.reshape((1,1776,6))\n",
        "x2_mri = x2_mri.reshape((1,1776,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjzEQguhXY-h"
      },
      "source": [
        "#Normalizing all data\n",
        "x1_mri = x1_mri/2000\n",
        "x2_mri = x2_mri/2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuzxonlkXa08"
      },
      "source": [
        "#Generating feature vectors\n",
        "inputs3 = Input(shape=(1776, 6))\n",
        "gru3 = GRU(6, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state = gru3(inputs3)\n",
        "model3 = Model(inputs=inputs3, outputs=whole_sequence_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MlA6pujXeaK"
      },
      "source": [
        "hippo_fv = model3.predict(x1_mri)\n",
        "entor_fv = model3.predict(x2_mri)\n",
        "print(hippo_fv)\n",
        "print(entor_fv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn_9QPUEq0YJ"
      },
      "source": [
        "##Converting MRI Feature Vectors and Labels to Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpFSVxnIqWae"
      },
      "source": [
        "hippo_fv_list = hippo_fv[0].tolist()\n",
        "print(hippo_fv_list)\n",
        "entor_fv_list = entor_fv[0].tolist()\n",
        "print(entor_fv_list)\n",
        "\n",
        "dic_hippo = {rids_mri[i]: hippo_fv_list[i] for i in range(len(rids_mri))}\n",
        "dic_entor = {rids_mri[i]: entor_fv_list[i] for i in range(len(rids_mri))}\n",
        "dic_mri_labels = {rids_mri[i]: labels_mri[i] for i in range(len(rids_mri))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9W59EVCq3Ne"
      },
      "source": [
        "print(dic_hippo)\n",
        "print(dic_entor)\n",
        "print(dic_mri_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGhe3b60s9Yj"
      },
      "source": [
        "##Join All Modalitites FVs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIHQaHgks_uV"
      },
      "source": [
        "final_list = []\n",
        "final_labels_list = []\n",
        "for i in dic_cogptmem.keys():\n",
        "  mergedlist = []\n",
        "  mergedlist = dic_abeta[i] + dic_tau[i] + dic_ptau[i] + dic_cogptmem[i] + dic_cogpttotal[i] + dic_hippo[i] + dic_entor[i] #+ dic_lapoe4[i] + dic_lage[i]\n",
        "  final_list.append(mergedlist)\n",
        "  final_labels_list.append(dic_cog_labels[i])\n",
        "\n",
        "print(len(final_list))\n",
        "print(len(final_list[0]))\n",
        "print(len(final_labels_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ytNBd8v9G2"
      },
      "source": [
        "positive = 0\n",
        "negative = 0\n",
        "for i in final_labels_list:\n",
        "  if i == 1:\n",
        "    positive = positive + 1\n",
        "  else:\n",
        "    negative = negative + 1\n",
        "\n",
        "print(\"Positive: \"+ str(positive))\n",
        "print(\"Negative: \"+ str(negative))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgxsQIHjwZL6"
      },
      "source": [
        "total_final_list = []\n",
        "total_final_labels = []\n",
        "counter = 0\n",
        "for i in range(len(final_labels_list)):\n",
        "  if final_labels_list[i] == 1:\n",
        "    total_final_list.append(final_list[i])\n",
        "    total_final_labels.append(final_labels_list[i])\n",
        "  elif final_labels_list[i] == 0:\n",
        "    if counter < 294:\n",
        "      total_final_list.append(final_list[i])\n",
        "      total_final_labels.append(final_labels_list[i])\n",
        "      counter = counter + 1\n",
        "print(len(total_final_list))\n",
        "print(total_final_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPTYfSVHjF8E"
      },
      "source": [
        "##Central GRU Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS29x3qMjYTe"
      },
      "source": [
        "total_final_list1 = np.array(total_final_list)\n",
        "#Reshaping for 3D input\n",
        "tots = total_final_list1.reshape((1,588,42))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJrnI5k7jFfe"
      },
      "source": [
        "#Generating feature vectors\n",
        "inputs3 = Input(shape=(588, 42))\n",
        "gru3 = GRU(42, return_sequences=True, return_state=True)\n",
        "whole_sequence_output, final_state = gru3(inputs3)\n",
        "model3 = Model(inputs=inputs3, outputs=whole_sequence_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7sBcCv-jL9d"
      },
      "source": [
        "total_final_list_fv = model3.predict(tots)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6LcQU5WlpL-"
      },
      "source": [
        "print(len(total_final_list_fv[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLwf3Z_-ubNy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# 70% training and 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(total_final_list_fv[0], np.array(total_final_labels), test_size=0.4,random_state=109)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAPDp-_pubjw"
      },
      "source": [
        "#SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "rf_params = {\n",
        "    'C': [1,10, 100],\n",
        "    \"kernel\":['linear','poly','rbf','sigmoid']\n",
        "}\n",
        "clf = svm.SVC(gamma='scale')\n",
        "grid = GridSearchCV(clf, rf_params, cv=3, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n",
        "print(\"Accuracy:\"+ str(grid.best_score_))"
      ],
      "metadata": {
        "id": "GA9N50if16Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoGVhQVMvHYG"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(C=100,kernel='linear') # Linear Kernel\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOh8gPVvv5HV"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eao_5lttvLyR"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score, cohen_kappa_score\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, permutation_test_score\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n",
        "#Printing Confusion Matrix\n",
        "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \", conf_matrix )\n",
        "\n",
        "#Printing F1 Score\n",
        "f1score = f1_score(y_test, y_pred, average='binary')\n",
        "print(\"F1 score: \", f1score)\n",
        "\n",
        "#Printing Cohen-Kappa score\n",
        "ckscore = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen-Kappa Score: \", ckscore)\n",
        "\n",
        "#Printing Precision-Recall Curve\n",
        "average_precision = average_precision_score(y_test, y_pred)\n",
        "disp = plot_precision_recall_curve(clf, X_test, y_test)\n",
        "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
        "                   'AP={0:0.2f}'.format(average_precision))\n",
        "\n",
        "\n",
        "#Printing ROC Curve\n",
        "metrics.plot_roc_curve(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#P-value\n",
        "_, _, p_value = permutation_test_score(clf, X_test, y_test, scoring=\"accuracy\", cv=None, n_permutations=200)\n",
        "\n",
        "print(p_value)"
      ],
      "metadata": {
        "id": "oGeyFf2U4TyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5xSu2cS1duP"
      },
      "source": [
        "#Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['sqrt',0.5],\n",
        "    'max_depth': [15,20,30,50],\n",
        "    #'min_samples_leaf': [1,2,4,8],\n",
        "    #\"bootstrap\":[True,False],\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "model = RandomForestClassifier(random_state=0)\n",
        "grid = GridSearchCV(model, rf_params, cv=3, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n",
        "print(\"Accuracy:\"+ str(grid.best_score_))"
      ],
      "metadata": {
        "id": "k8QhYclR1yF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfH07cHD1fqS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model with 100 trees\n",
        "model = RandomForestClassifier(criterion='entropy',\n",
        "                               max_depth=15,\n",
        "                               n_estimators=200, \n",
        "                               bootstrap = True,\n",
        "                               max_features = 0.5)\n",
        "# Fit on training data\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJAa3571tM4"
      },
      "source": [
        "# Actual class predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cLShVND1l8d"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n",
        "#Printing Confusion Matrix\n",
        "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \", conf_matrix )\n",
        "\n",
        "#Printing F1 Score\n",
        "f1score = f1_score(y_test, y_pred, average='binary')\n",
        "print(\"F1 score: \", f1score)\n",
        "\n",
        "#Printing Cohen-Kappa score\n",
        "ckscore = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen-Kappa Score: \", ckscore)\n",
        "\n",
        "#Printing Precision-Recall Curve\n",
        "average_precision = average_precision_score(y_test, y_pred)\n",
        "disp = plot_precision_recall_curve(model, X_test, y_test)\n",
        "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
        "                   'AP={0:0.2f}'.format(average_precision))\n",
        "\n",
        "\n",
        "#Printing ROC Curve\n",
        "metrics.plot_roc_curve(model, X_test, y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#P-value\n",
        "_, _, p_value = permutation_test_score(model, X_test, y_test, scoring=\"accuracy\", cv=None, n_permutations=200)\n",
        "\n",
        "print(p_value)"
      ],
      "metadata": {
        "id": "t4WqcVKP9Ab0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugVWOXP12Dut"
      },
      "source": [
        "#Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVBspFbM2qFc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import export_graphviz\n",
        "#from sklearn.externals.six import StringIO \n",
        "from IPython.display import Image \n",
        "from pydot import graph_from_dot_data\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#create a dictionary of all values we want to test\n",
        "param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 10)}\n",
        "# decision tree model\n",
        "dtree_model=DecisionTreeClassifier()\n",
        "#use gridsearch to test all values\n",
        "dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=5)\n",
        "#fit model to data\n",
        "dtree_gscv.fit(X_train, y_train)\n",
        "print(dtree_gscv.best_params_)\n",
        "print(\"Accuracy:\"+ str(dtree_gscv.best_score_))"
      ],
      "metadata": {
        "id": "DiCgUoZl18xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryejl0752Kug"
      },
      "source": [
        "dt = DecisionTreeClassifier(criterion='gini',max_depth=5)\n",
        "dt.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcxdNy4C2xUt"
      },
      "source": [
        "y_pred = dt.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr_WfdSa2KJL"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n",
        "#Printing Confusion Matrix\n",
        "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \", conf_matrix )\n",
        "\n",
        "#Printing F1 Score\n",
        "f1score = f1_score(y_test, y_pred, average='binary')\n",
        "print(\"F1 score: \", f1score)\n",
        "\n",
        "#Printing Cohen-Kappa score\n",
        "ckscore = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen-Kappa Score: \", ckscore)\n",
        "\n",
        "#Printing Precision-Recall Curve\n",
        "average_precision = average_precision_score(y_test, y_pred)\n",
        "disp = plot_precision_recall_curve(dt, X_test, y_test)\n",
        "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
        "                   'AP={0:0.2f}'.format(average_precision))\n",
        "\n",
        "\n",
        "#Printing ROC Curve\n",
        "metrics.plot_roc_curve(dt, X_test, y_test)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#P-value\n",
        "_, _, p_value = permutation_test_score(dt, X_test, y_test, scoring=\"accuracy\", cv=None, n_permutations=200)\n",
        "\n",
        "print(p_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making Combined Graphs"
      ],
      "metadata": {
        "id": "9074Cdg9kYTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC Curve\n",
        "\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "classifiers = [clf, dt, model]\n",
        "ax = plt.gca()\n",
        "for i in classifiers:\n",
        "    plot_roc_curve(i, X_test, y_test, ax=ax)"
      ],
      "metadata": {
        "id": "o4W_-72ykazn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision Recall Curve\n",
        "\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "classifiers = [clf, dt, model]\n",
        "ax = plt.gca()\n",
        "for i in classifiers:\n",
        "    plot_precision_recall_curve(i, X_test, y_test, ax=ax)"
      ],
      "metadata": {
        "id": "R0S_e0CikjNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}